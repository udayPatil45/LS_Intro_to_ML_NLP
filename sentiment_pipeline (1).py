# -*- coding: utf-8 -*-
"""sentiment_pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QEke4jiBg46LPtgafRyEeFs4u2Dn1X4O

# ASSIGNMENT 3
"""

# imporing required modules
import os
import pandas as pd
import numpy as np
from datasets import Dataset, load_metric
from transformers import (
    BertTokenizer,
    BertForSequenceClassification,
    Trainer,
    TrainingArguments,
)
import evaluate
import torch

# -------------------- Step 1: Load Dataset from imdb datasets --------------------
# Load all 3 splits
train_df = pd.read_parquet("/content/train-00000-of-00001.parquet")
val_df = pd.read_parquet("/content/validation-00000-of-00001.parquet")
test_df = pd.read_parquet("/content/test-00000-of-00001.parquet")

# Convert to Hugging Face Datasets
train_dataset = Dataset.from_pandas(train_df)
val_dataset = Dataset.from_pandas(val_df)
test_dataset = Dataset.from_pandas(test_df)

train_df.head(5)

# -------------------- Step 2: Tokenization --------------------
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

# Identify the correct text column
print("Train dataset columns:", train_dataset.column_names)

def tokenize_function(example):
    return tokenizer(
        example["verse_text"],
        padding="max_length",
        truncation=True,
        max_length=128
    )

tokenized_train = train_dataset.map(tokenize_function, batched=True)
tokenized_val = val_dataset.map(tokenize_function, batched=True)
tokenized_test = test_dataset.map(tokenize_function, batched=True)

# Remove unnecessary columns
columns_to_remove = ["id", "verse_text"]
if "__index_level_0__" in train_dataset.column_names:
    columns_to_remove.append("__index_level_0__")

tokenized_train = tokenized_train.remove_columns(columns_to_remove)
tokenized_val = tokenized_val.remove_columns(columns_to_remove)
tokenized_test = tokenized_test.remove_columns(columns_to_remove)

# Set PyTorch format
tokenized_train.set_format("torch")
tokenized_val.set_format("torch")
tokenized_test.set_format("torch")

# importing the model
model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=3)

# -------------------- Step 4: Define Metrics --------------------
accuracy = evaluate.load("accuracy")
f1 = evaluate.load("f1")

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=1)
    return {
        "accuracy": accuracy.compute(predictions=predictions, references=labels)["accuracy"],
        "f1": f1.compute(predictions=predictions, references=labels, average="weighted")["f1"]
    }

# -------------------- Step 5: Training Configuration --------------------
training_args = TrainingArguments(
    output_dir="./results",
    eval_strategy="epoch",
    save_strategy="epoch",
    num_train_epochs=2,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    logging_steps=100,
    save_total_limit=2,
    weight_decay=0.01,
    load_best_model_at_end=True,
)

!pip install -U transformers
import transformers
print(transformers.__version__)  # just to make sure the version is new

# -------------------- Step 6: Train the Model --------------------
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train,
    eval_dataset=tokenized_val,
    compute_metrics=compute_metrics,
)

from transformers import Trainer

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train,
    eval_dataset=tokenized_val,
    compute_metrics=compute_metrics,
)

# -------------------- Step 7: Evaluate on Test Set --------------------
metrics = trainer.evaluate(tokenized_test)
print("Test set metrics:", metrics)

# -------------------- Step 8: Save Model --------------------
model.save_pretrained("poem_sentiment_bert")
tokenizer.save_pretrained("poem_sentiment_bert")

# -------------------- Step 9: Inference Example --------------------
from transformers import pipeline

# Load pipeline from saved model
sentiment_pipeline = pipeline("sentiment-analysis", model="poem_sentiment_bert", tokenizer="poem_sentiment_bert")

# Try on a new sentence
example_text = "This poem is absolutely beautiful and uplifting."
print(sentiment_pipeline(example_text))



